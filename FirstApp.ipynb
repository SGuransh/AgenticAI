{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6ed476e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY', '')\n",
    "os.environ['LANGCHAIN_API_KEY'] = os.getenv('LANGCHAIN_API_KEY', '')\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = \"true\"\n",
    "os.environ['LANGCHAIN_PROJECT'] = os.getenv('LANGCHAIN_PROJECT', 'default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0850cdd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "loader = WebBaseLoader(\"https://en.wikipedia.org/wiki/Large_language_model\")\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3544804d",
   "metadata": {},
   "source": [
    "Load -> Docs -> Divide our text into chunks -> text -> vectors -> vector Embedding -> Vector Store DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3897b119",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "docs = text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4978f70d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f8f1016",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs1 = docs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a957efa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='Large language model - Wikipedia\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJump to content\\n\\n\\n\\n\\n\\n\\n\\nMain menu\\n\\n\\n\\n\\n\\nMain menu\\nmove to sidebar\\nhide\\n\\n\\n\\n\\t\\tNavigation\\n\\t\\n\\n\\nMain pageContentsCurrent eventsRandom articleAbout WikipediaContact us\\n\\n\\n\\n\\n\\n\\t\\tContribute\\n\\t\\n\\n\\nHelpLearn to editCommunity portalRecent changesUpload fileSpecial pages\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAppearance\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nDonate\\n\\nCreate account\\n\\nLog in\\n\\n\\n\\n\\n\\n\\n\\n\\nPersonal tools\\n\\n\\n\\n\\n\\nDonate Create account Log in\\n\\n\\n\\n\\n\\n\\t\\tPages for logged out editors learn more\\n\\n\\n\\nContributionsTalk\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nContents\\nmove to sidebar\\nhide\\n\\n\\n\\n\\n(Top)\\n\\n\\n\\n\\n\\n1\\nHistory\\n\\n\\n\\n\\n\\n\\n\\n\\n2\\nDataset preprocessing\\n\\n\\n\\n\\nToggle Dataset preprocessing subsection\\n\\n\\n\\n\\n\\n2.1\\nTokenization\\n\\n\\n\\n\\n\\n\\n2.1.1\\nBPE\\n\\n\\n\\n\\n\\n\\n\\n\\n2.1.2\\nProblems\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n2.2\\nDataset cleaning\\n\\n\\n\\n\\n\\n\\n\\n\\n2.3\\nSynthetic data\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n3\\nTraining and architecture\\n\\n\\n\\n\\nToggle Training and architecture subsection\\n\\n\\n\\n\\n\\n3.1\\nReinforcement learning from human feedback'),\n",
       " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='2.2\\nDataset cleaning\\n\\n\\n\\n\\n\\n\\n\\n\\n2.3\\nSynthetic data\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n3\\nTraining and architecture\\n\\n\\n\\n\\nToggle Training and architecture subsection\\n\\n\\n\\n\\n\\n3.1\\nReinforcement learning from human feedback\\n\\n\\n\\n\\n\\n\\n\\n\\n3.2\\nInstruction tuning\\n\\n\\n\\n\\n\\n\\n\\n\\n3.3\\nMixture of experts\\n\\n\\n\\n\\n\\n\\n\\n\\n3.4\\nPrompt engineering, attention mechanism, and context window\\n\\n\\n\\n\\n\\n\\n\\n\\n3.5\\nInfrastructure\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n4\\nTraining cost\\n\\n\\n\\n\\n\\n\\n\\n\\n5\\nTool use\\n\\n\\n\\n\\n\\n\\n\\n\\n6\\nAgency\\n\\n\\n\\n\\n\\n\\n\\n\\n7\\nCompression\\n\\n\\n\\n\\n\\n\\n\\n\\n8\\nMultimodality\\n\\n\\n\\n\\n\\n\\n\\n\\n9\\nReasoning\\n\\n\\n\\n\\n\\n\\n\\n\\n10\\nProperties\\n\\n\\n\\n\\nToggle Properties subsection\\n\\n\\n\\n\\n\\n10.1\\nScaling laws\\n\\n\\n\\n\\n\\n\\n\\n\\n10.2\\nEmergent abilities\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n11\\nInterpretation\\n\\n\\n\\n\\nToggle Interpretation subsection\\n\\n\\n\\n\\n\\n11.1\\nStudying a replacement model\\n\\n\\n\\n\\n\\n\\n\\n\\n11.2\\nExplainability\\n\\n\\n\\n\\n\\n\\n\\n\\n11.3\\nUnderstanding and intelligence\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n12\\nEvaluation\\n\\n\\n\\n\\nToggle Evaluation subsection\\n\\n\\n\\n\\n\\n12.1\\nPerplexity\\n\\n\\n\\n\\n\\n\\n12.1.1\\nMeasures\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n12.2\\nBenchmarks\\n\\n\\n\\n\\n\\n\\n12.2.1\\nDatasets\\n\\n\\n\\n\\n\\n\\n\\n\\n12.2.2\\nAdversarial evaluations\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n13\\nWider impact'),\n",
       " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='Toggle Evaluation subsection\\n\\n\\n\\n\\n\\n12.1\\nPerplexity\\n\\n\\n\\n\\n\\n\\n12.1.1\\nMeasures\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n12.2\\nBenchmarks\\n\\n\\n\\n\\n\\n\\n12.2.1\\nDatasets\\n\\n\\n\\n\\n\\n\\n\\n\\n12.2.2\\nAdversarial evaluations\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n13\\nWider impact\\n\\n\\n\\n\\nToggle Wider impact subsection\\n\\n\\n\\n\\n\\n13.1\\nMemorization and copyright\\n\\n\\n\\n\\n\\n\\n\\n\\n13.2\\nSecurity\\n\\n\\n\\n\\n\\n\\n\\n\\n13.3\\nAlgorithmic bias\\n\\n\\n\\n\\n\\n\\n13.3.1\\nStereotyping\\n\\n\\n\\n\\n\\n\\n\\n\\n13.3.2\\nSelection bias\\n\\n\\n\\n\\n\\n\\n\\n\\n13.3.3\\nPolitical bias\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n13.4\\nEnergy demands\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n14\\nSee also\\n\\n\\n\\n\\n\\n\\n\\n\\n15\\nReferences\\n\\n\\n\\n\\n\\n\\n\\n\\n16\\nFurther reading\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nToggle the table of contents\\n\\n\\n\\n\\n\\n\\n\\nLarge language model\\n\\n\\n\\n56 languages'),\n",
       " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='13.4\\nEnergy demands\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n14\\nSee also\\n\\n\\n\\n\\n\\n\\n\\n\\n15\\nReferences\\n\\n\\n\\n\\n\\n\\n\\n\\n16\\nFurther reading\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nToggle the table of contents\\n\\n\\n\\n\\n\\n\\n\\nLarge language model\\n\\n\\n\\n56 languages\\n\\n\\n\\n\\nAfrikaansالعربيةAragonésAzərbaycancaবাংলা閩南語 / Bân-lâm-gúBoarischBosanskiCatalàČeštinaDanskDeutschΕλληνικάEspañolEsperantoEuskaraفارسیFrançaisGaeilgeGalego한국어हिन्दीIdoBahasa IndonesiaIsiZuluItalianoעבריתҚазақшаMagyarМакедонскиМонголNederlands日本語Norsk nynorskPolskiPortuguêsQaraqalpaqshaRomânăRuna SimiРусскийShqipSimple EnglishSlovenščinaکوردیСрпски / srpskiSuomiTagalogతెలుగుไทยTürkçeУкраїнськаئۇيغۇرچە / UyghurcheTiếng Việt文言粵語中文\\n\\nEdit links\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nArticleTalk\\n\\n\\n\\n\\n\\nEnglish\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nReadEditView history\\n\\n\\n\\n\\n\\n\\n\\nTools\\n\\n\\n\\n\\n\\nTools\\nmove to sidebar\\nhide\\n\\n\\n\\n\\t\\tActions\\n\\t\\n\\n\\nReadEditView history\\n\\n\\n\\n\\n\\n\\t\\tGeneral\\n\\t\\n\\n\\nWhat links hereRelated changesUpload filePermanent linkPage informationCite this pageGet shortened URLDownload QR code\\n\\n\\n\\n\\n\\n\\t\\tPrint/export\\n\\t\\n\\n\\nDownload as PDFPrintable version'),\n",
       " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='General\\n\\t\\n\\n\\nWhat links hereRelated changesUpload filePermanent linkPage informationCite this pageGet shortened URLDownload QR code\\n\\n\\n\\n\\n\\n\\t\\tPrint/export\\n\\t\\n\\n\\nDownload as PDFPrintable version\\n\\n\\n\\n\\n\\n\\t\\tIn other projects\\n\\t\\n\\n\\nWikimedia CommonsWikidata item\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAppearance\\nmove to sidebar\\nhide\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nFrom Wikipedia, the free encyclopedia')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ae3b6289",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "104dea6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "vectorstoredb = FAISS.from_documents(docs1, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "364fe031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM initialized with model: gpt-4.1-nano\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4.1-nano\")\n",
    "print(\"LLM initialized with model:\", llm.model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1f698e2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableLambda(format_docs)\n",
       "}), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])\n",
       "| ChatPromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template='\\nYou are a helpful assistant. Answer the question based on the provided context.\\n<context>\\n{context}\\n</context>\\n    '), additional_kwargs={})])\n",
       "| ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x0000012265F33340>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x0000012265F33250>, root_client=<openai.OpenAI object at 0x0000012265F33850>, root_async_client=<openai.AsyncOpenAI object at 0x0000012265F303A0>, model_name='gpt-4.1-nano', model_kwargs={}, openai_api_key=SecretStr('**********'))\n",
       "| StrOutputParser(), kwargs={}, config={'run_name': 'stuff_documents_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt=ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "You are a helpful assistant. Answer the question based on the provided context.\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)\n",
    "document_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fd81f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "document_chain.invoke(\n",
    "    {\n",
    "\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f83508b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.faiss.FAISS at 0x1221a039360>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstoredb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5ab3e84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever=vectorstoredb.as_retriever()\n",
    "from langchain.chains import create_retrieval_chain\n",
    "retrieval_chain = create_retrieval_chain(retriever, document_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "562c8a8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableBinding(bound=RunnableLambda(lambda x: x['input'])\n",
       "           | VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000001221A039360>, search_kwargs={}), kwargs={}, config={'run_name': 'retrieve_documents'}, config_factories=[])\n",
       "})\n",
       "| RunnableAssign(mapper={\n",
       "    answer: RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "              context: RunnableLambda(format_docs)\n",
       "            }), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])\n",
       "            | ChatPromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template='\\nYou are a helpful assistant. Answer the question based on the provided context.\\n<context>\\n{context}\\n</context>\\n    '), additional_kwargs={})])\n",
       "            | ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x0000012265F33340>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x0000012265F33250>, root_client=<openai.OpenAI object at 0x0000012265F33850>, root_async_client=<openai.AsyncOpenAI object at 0x0000012265F303A0>, model_name='gpt-4.1-nano', model_kwargs={}, openai_api_key=SecretStr('**********'))\n",
       "            | StrOutputParser(), kwargs={}, config={'run_name': 'stuff_documents_chain'}, config_factories=[])\n",
       "  }), kwargs={}, config={'run_name': 'retrieval_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieval_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "659a3059",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = retrieval_chain.invoke({\"input\": \"What is a large language model?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3b995344",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Based on the provided Wikipedia content, a large language model (LLM) is a type of artificial intelligence model designed to understand and generate human language. The article covers various aspects of LLMs, including their development history, dataset preprocessing steps such as tokenization and dataset cleaning, training architectures like reinforcement learning from human feedback, and considerations regarding their wider impact, including ethical and environmental concerns. The structure also addresses evaluation methods, properties, interpretation, and additional features like multimodality and reasoning abilities.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9cfd4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
